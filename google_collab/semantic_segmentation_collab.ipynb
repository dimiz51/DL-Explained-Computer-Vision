{"cells":[{"cell_type":"markdown","metadata":{"id":"qMaXHuIoLTQh"},"source":["# Import and Google Drive mount"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34166,"status":"ok","timestamp":1703528156436,"user":{"displayName":"DLExplained","userId":"13047394520930452036"},"user_tz":-60},"id":"O4TdKKYALXiX","outputId":"8aace4a6-d5da-499d-e048-895b57cb8876"},"outputs":[],"source":["# Mount Google Drive\n","import os\n","from google.colab import drive\n","\n","# Check if the /content/drive directory exists\n","drive_mounted = os.path.exists('/content/drive')\n","\n","if drive_mounted:\n","    print(\"Google Drive is already mounted.\")\n","else:\n","    drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1703528307634,"user":{"displayName":"DLExplained","userId":"13047394520930452036"},"user_tz":-60},"id":"mPN0Ika7iICc"},"outputs":[],"source":["os.chdir('/content/drive/MyDrive/DL_Explained/computer_vision')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":543,"status":"ok","timestamp":1703529447591,"user":{"displayName":"DLExplained","userId":"13047394520930452036"},"user_tz":-60},"id":"wsFdzjPTh9sD"},"outputs":[],"source":["import sys\n","sys.path.append('../')\n","try:\n","  import tensorflow_addons as tfa\n","  import keras_cv\n","except:\n","  !pip install keras_cv\n","  !pip install tensorflow-addons\n","  import tensorflow_addons as tfa\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","from helper import set_model_config\n","from helper import plot_loss, visualize_segmentation_predictions\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from helper import plot_loss\n","from keras import layers\n","from keras.models import Model\n","'''Create a random seed generator for randomized TF ops'''\n","rng = tf.random.Generator.from_seed(123, alg='philox')"]},{"cell_type":"markdown","metadata":{"id":"K5m-SLtsh9sG"},"source":["# Load the Dataset and preview basic info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_cWLpEvmh9sI"},"outputs":[],"source":["# Load the Oxford pets\n","(train_ds, val_ds, test_ds), info = tfds.load(\n","    'oxford_iiit_pet:3.*.*',\n","    split=['train+test[:50%]', 'test[50%:80%]', 'test[80%:100%]'],\n","    with_info=True)\n","\n","# Access and print dataset information\n","print(\"Oxford pets dataset information:\")\n","print(f\"Number of classes: {info.features['label'].num_classes}\")\n","print(f\"Class names: {info.features['label'].names}\")\n","print(f\"Number of training examples: {info.splits['train'].num_examples}\")\n","print(f\"Dataset splits: {list(info.splits.keys())}\")\n","print(f\"Dataset description: {info.description}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":421,"status":"ok","timestamp":1703528547610,"user":{"displayName":"DLExplained","userId":"13047394520930452036"},"user_tz":-60},"id":"29vSpt5Kh9sI","outputId":"44dbcd71-5441-401d-8392-43f8766c1cc5"},"outputs":[],"source":["info._features"]},{"cell_type":"markdown","metadata":{"id":"tFr_nNJpLkwK"},"source":["# Set model config"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1703528556158,"user":{"displayName":"DLExplained","userId":"13047394520930452036"},"user_tz":-60},"id":"ZgYPA2ANLm0U","outputId":"740daa27-574b-457f-b1f3-ca0a517b1a06"},"outputs":[],"source":["config = set_model_config(\"oxford_unet\")\n","config"]},{"cell_type":"markdown","metadata":{"id":"tXteiClDh9sI"},"source":["# Create data pre-processing pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":801,"status":"ok","timestamp":1703529580477,"user":{"displayName":"DLExplained","userId":"13047394520930452036"},"user_tz":-60},"id":"OyAbtrAsh9sJ"},"outputs":[],"source":["# Apply augmentations to both mask and images for trainset\n","def augmentations(image, mask):\n","    image = tf.image.resize(image , (224,224))\n","    mask = tf.image.resize(mask, (224,224))\n","\n","    # Random horizontal flip for data augmentation\n","    if tf.random.uniform(()) > 0.5:\n","        image = tf.image.flip_left_right(image)\n","        mask = tf.image.flip_left_right(mask)\n","\n","    return image, tf.cast(mask, dtype = tf.uint8)\n","\n","# Resize mask/images pre-process for inference\n","def resize_inference(image, mask):\n","    image = tf.image.resize(image , (224,224))\n","    mask = tf.image.resize(mask, (224,224))\n","\n","    return image, tf.cast(mask, dtype = tf.uint8)\n","\n","# Convert to binary\n","def binary_mask(mask):\n","    mask = tf.cast(mask, dtype = tf.int32)\n","    converted_mask = tf.where(tf.equal(mask, 1), 1, mask)\n","    converted_mask = tf.where(tf.equal(mask, 2), 0, converted_mask)\n","    converted_mask = tf.where(tf.equal(mask, 3), 0, converted_mask)\n","    return tf.cast(converted_mask, dtype = tf.uint8)\n","\n","# Pre-process trainset\n","def preprocess_train(element):\n","    image = tf.image.convert_image_dtype(element['image'], tf.float32)\n","    segmentation_mask = tf.image.convert_image_dtype(element['segmentation_mask'], tf.uint8)\n","    segmentation_mask = binary_mask(segmentation_mask)\n","\n","    # Apply augmentations\n","    image, segmentation_mask = augmentations(image, segmentation_mask)\n","\n","    return image, segmentation_mask\n","\n","# Pre-process val/test sets\n","def preprocess_val_test(element):\n","    image = tf.image.convert_image_dtype(element['image'], tf.float32)\n","    segmentation_mask = tf.image.convert_image_dtype(element['segmentation_mask'], tf.uint8)\n","    segmentation_mask = binary_mask(segmentation_mask)\n","\n","\n","    # Resize image and mask for inference\n","    image, segmentation_mask = resize_inference(image, segmentation_mask)\n","\n","    return image, segmentation_mask\n","\n","train_dataset = train_ds.map(preprocess_train, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n","train_dataset = train_dataset.batch(config['batch_size'])\n","train_dataset = train_dataset.shuffle(buffer_size=config['batch_size'] * 6)\n","train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","\n","validation_dataset = val_ds.map(preprocess_val_test, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n","validation_dataset = validation_dataset.batch(config['batch_size'])\n","validation_dataset = validation_dataset.shuffle(buffer_size=config['batch_size'] * 6)\n","validation_dataset = validation_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","\n","\n","test_dataset = test_ds.map(preprocess_val_test)\n","test_dataset = test_dataset.batch(config['batch_size'])\n","test_dataset = test_dataset.shuffle(buffer_size=8 * 6)\n","test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"]},{"cell_type":"markdown","metadata":{"id":"r4wOUm6Kh9sJ"},"source":["# Visualize a few samples from the Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQ-ZaEith9sK"},"outputs":[],"source":["def visualize_samples(dataset, num_samples=3):\n","    # Take the first 'num_samples' samples from the dataset\n","    sample_dataset = dataset.take(num_samples)\n","\n","    # Create a subplot for displaying images in the grid\n","    fig, axes = plt.subplots(num_samples, 2, figsize=(10, 5 * num_samples))\n","\n","    # Iterate through the samples dataset\n","    for i, batch in enumerate(sample_dataset):\n","        image = batch['image'].numpy().astype(int)\n","        label = batch['label'].numpy().astype(int)\n","        segmentation_mask = batch['segmentation_mask'].numpy().astype(int)\n","\n","        # Plot original image\n","        axes[i, 0].imshow(image)\n","        axes[i, 0].set_title(f'Original Image - Sample {i + 1}')\n","        axes[i, 0].axis('off')\n","\n","        # Plot segmentation mask\n","        axes[i, 1].imshow(segmentation_mask[:, :, 0], cmap='gray')\n","        axes[i, 1].set_title(f'Segmentation Mask - Sample {i + 1}')\n","        axes[i, 1].axis('off')\n","\n","with plt.style.context('dark_background'):\n","  visualize_samples(train_ds)"]},{"cell_type":"markdown","metadata":{"id":"W7A9r8jph9sK"},"source":["# U-net Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nAq-LJAhh9sL"},"outputs":[],"source":["from tensorflow.keras import layers\n","from tensorflow.keras.applications import MobileNetV2\n","\n","# Unet with pre-trained encoder\n","def unet_model(img_size, num_classes):\n","    base_model = tf.keras.applications.MobileNetV2(input_shape=img_size, include_top=False)\n","\n","    names = ['block_1_expand_relu', 'block_3_expand_relu', 'block_6_expand_relu',\n","         'block_13_expand_relu', 'block_16_expand_relu']\n","    encoder_layers = [base_model.get_layer(name).output for name in names]\n","\n","    down_sample = tf.keras.Model(base_model.input, encoder_layers)\n","    down_sample.trainable = False\n","\n","    # Downsampling through the model\n","    inputs = keras.Input(shape = img_size)\n","    x = inputs\n","    skips = down_sample(x)\n","    x = skips[-1]\n","    skips = reversed(skips[:-1])\n","\n","    up_stack = [layers.Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same', activation='relu', kernel_initializer='he_normal'),\n","                layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', activation='relu', kernel_initializer='he_normal'),\n","                layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu', kernel_initializer='he_normal'),\n","                layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu', kernel_initializer='he_normal'),\n","              ]\n","\n","    # Upsampling and establishing the skip connections\n","    for up, skip in zip(up_stack, skips):\n","        x = up(x)\n","        concat = tf.keras.layers.Concatenate()\n","        x = concat([x, skip])\n","\n","    conv10 = layers.Conv2DTranspose(1, 3, strides=2 , padding='same')(x)\n","\n","    # Create the UNet model\n","    model = keras.models.Model(inputs=inputs, outputs=[conv10])\n","\n","    # Compile the model\n","    model.compile(optimizer=keras.optimizers.Adam(learning_rate=config['learning_rate']),\n","                  loss=keras.losses.BinaryCrossentropy(from_logits = True),\n","                  metrics=[tf.keras.metrics.BinaryIoU(target_class_ids=[0, 1],\n","                                                      name = 'IoU'),\n","                           'accuracy'])\n","\n","    return model\n","\n","model = unet_model((224, 224, 3), config['n_classes'])\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"LfV5dyllPVnM"},"source":["# Set training callbacks and train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bnIs11D08esN"},"outputs":[],"source":["# Set a learning rate scheduler to progressively reduce the learning rate as learning plateaus\n","lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n","                                 patience=5, min_lr=0.0001)\n","\n","# Always save the best model\n","saving_cb = ModelCheckpoint(\n","    filepath='./trained_models/oxford_segmentation/best_weights.h5',\n","    save_weights_only=True,\n","    monitor='val_loss',\n","    mode='min',\n","    save_best_only=True,\n","    verbose=1\n",")\n","\n","# Train the model with class weights and EarlyStopping\n","history = model.fit(train_dataset, epochs=2, validation_data=validation_dataset, callbacks = [lr_scheduler, saving_cb])"]},{"cell_type":"markdown","metadata":{"id":"sVQ8lAF3Qk3m"},"source":["# Plot losses and save the final model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W03kmictQkUG"},"outputs":[],"source":["# Plot with dark backgorund\n","with plt.style.context('dark_background'):\n","    plot_loss(history, model_type = 'segmentation')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15703,"status":"ok","timestamp":1703529643815,"user":{"displayName":"DLExplained","userId":"13047394520930452036"},"user_tz":-60},"id":"k4ZS89-ZPyK4"},"outputs":[],"source":["# Save the final model\n","model.save(\"./trained_models/oxford_segmentation/oxford_unet\")"]},{"cell_type":"markdown","metadata":{"id":"Lb2HSXnqROBi"},"source":["# Make some predictions on the test set and visualize them"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M3nlgaA5RRIo"},"outputs":[],"source":["with plt.style.context('dark_background'):\n","  visualize_segmentation_predictions(test_dataset, model, num_samples=3, threshold=0.5)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
