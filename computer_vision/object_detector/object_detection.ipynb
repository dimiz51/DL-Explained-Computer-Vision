{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from helper import set_model_config, plot_loss\n",
    "from helper import visualize_object_predictions, visualize_object_detection_samples\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config  = set_model_config(model_name='pascal_yolo')\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Pascal-Voc dataset\n",
    "\n",
    "# Get the class mapping dictionary\n",
    "def get_class_mapping(dataset_info):\n",
    "    class_mapping = {i: class_info for i, class_info in enumerate(dataset_info.features['objects']['label'].names)}\n",
    "    return class_mapping\n",
    "\n",
    "\n",
    "# Unpackage the raw tfdf formats into Keras-CV format\n",
    "def unpackage_raw_tfds_inputs(inputs, bounding_box_format):\n",
    "    image = inputs[\"image\"]\n",
    "    boxes = keras_cv.bounding_box.convert_format(\n",
    "        inputs[\"objects\"][\"bbox\"],\n",
    "        images=image,\n",
    "        source=\"rel_yxyx\",\n",
    "        target=bounding_box_format,\n",
    "    )\n",
    "    \n",
    "    bounding_boxes = {\n",
    "        \"classes\": tf.cast(inputs[\"objects\"][\"label\"], dtype = tf.float32),\n",
    "        \"boxes\": tf.cast(boxes, dtype=tf.int32)\n",
    "    }\n",
    "    return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}\n",
    "\n",
    "# Unpack batch from dataset to tuple format function\n",
    "def unpack_batch_dicts(inputs):\n",
    "    # Define the operation to cast values to tf.int32\n",
    "    def cast_to_int32(value):\n",
    "        return tf.cast(value, dtype=tf.int32)\n",
    "    \n",
    "    correct_gt = {\"classes\":  tf.ragged.map_flat_values(cast_to_int32, inputs['bounding_boxes']['classes']),\n",
    "                    \"boxes\":  inputs['bounding_boxes']['boxes']}\n",
    "    return inputs[\"images\"], bounding_box.to_dense(correct_gt, max_boxes = 100)\n",
    "\n",
    "# Custom dataloader, compatible with Keras-CV, applies shuffling and batching\n",
    "def load_pascal_voc(split, dataset, bounding_box_format):\n",
    "    ds, ds_info  = tfds.load(dataset, split=split, with_info=True, shuffle_files=True)\n",
    "    \n",
    "    # Convert the images/bboxes to the Keras-CV API format\n",
    "    ds = ds.map(\n",
    "        lambda x: unpackage_raw_tfds_inputs(x, bounding_box_format=bounding_box_format),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "    \n",
    "    # Create ragged batches(with elems of different sizes) #TODO: Do we need this?\n",
    "    if split == 'test':\n",
    "        ds = ds.ragged_batch(8, drop_remainder=True)\n",
    "    else:\n",
    "        ds = ds.shuffle(config['batch_size'] * 4, reshuffle_each_iteration=True)\n",
    "        ds = ds.ragged_batch(config['batch_size'], drop_remainder=True)\n",
    "    \n",
    "    return ds,ds_info\n",
    "\n",
    "# Define augmenter module using custom object detection friendly ops from Keras-CV\n",
    "augmenter = keras.Sequential(\n",
    "    layers=[\n",
    "        keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xywh\"),\n",
    "        keras_cv.layers.RandomShear(\n",
    "            x_factor=0.2, y_factor=0.2, bounding_box_format=\"xywh\"\n",
    "        ),\n",
    "        keras_cv.layers.JitteredResize(\n",
    "            target_size=(480, 480), scale_factor=(0.75, 1.3), bounding_box_format=\"xywh\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# # Inference inputs pre-processing for our test and validation sets\n",
    "inf_preprocess = keras_cv.layers.JitteredResize(target_size=(480, 480),\n",
    "                                              scale_factor=(0.75, 1.3),\n",
    "                                              bounding_box_format=\"xywh\",\n",
    "                                            )\n",
    "\n",
    "# Load the three different pre-processed splits of our dataset\n",
    "ds_train, ds_info = load_pascal_voc(\n",
    "    split=\"train\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"\n",
    ")\n",
    "ds_val, _ = load_pascal_voc(\n",
    "    split=\"validation\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"\n",
    ")\n",
    "ds_test, _ = load_pascal_voc(\n",
    "    split=\"test\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset information and samples visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----Pascal-Voc dataset information-----:\")\n",
    "print(f\"Number of training examples: {ds_info.splits['train'].num_examples}\")\n",
    "print(f\"Number of validation examples: {ds_info.splits['validation'].num_examples}\")\n",
    "print(f\"Number of test examples: {ds_info.splits['test'].num_examples}\")\n",
    "print(f\"Dataset splits available: {list(ds_info.splits.keys())}\")\n",
    "print(\"Number of Classes:\", len(ds_info.features[\"objects\"][\"label\"].names))\n",
    "print(f\"Class names: {ds_info.features['objects']['label'].names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some samples from the dataset\n",
    "with plt.style.context('dark_background'):\n",
    "    visualize_object_detection_samples(ds_train, value_range=(0, 255), rows=2, cols=4, bounding_box_format=\"xywh\", class_mapping=get_class_mapping(ds_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply augmentations and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentations and set prefetch option on training set\n",
    "ds_train = ds_train.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.map(unpack_batch_dicts, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Pre-process validation and test set\n",
    "ds_val = ds_val.map(inf_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.map(unpack_batch_dicts, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(inf_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.shuffle(ds_info.splits['test'].num_examples)\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a backbone architecture from Keras-CV and create our own YoloV8 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained, on the CoCo dataset, YoloV8 model\n",
    "backbone =  keras_cv.models.YOLOV8Backbone.from_preset(\"yolo_v8_xs_backbone\")\n",
    "backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our custom YOLO model from the smallest available backbone\n",
    "\n",
    "# Set the Non-Maximum Supression module for predictions decoding\n",
    "# NOTE: Tune confidence threshold for predictions to pass NMS\n",
    "# NOTE: Decrease the required threshold to make predictions get pruned out\n",
    "prediction_decoder = keras_cv.layers.NonMaxSuppression(\n",
    "    bounding_box_format=\"xywh\",\n",
    "    from_logits=True,\n",
    "    iou_threshold=0.3,\n",
    "    confidence_threshold=0.7,\n",
    ")\n",
    "\n",
    "model = keras_cv.models.YOLOV8Detector(\n",
    "    num_classes=len(get_class_mapping(ds_info)),\n",
    "    bounding_box_format=\"xywh\",\n",
    "    backbone=backbone,\n",
    "    fpn_depth = 1,\n",
    "    prediction_decoder = prediction_decoder\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set training callbacks and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Early Stopping strategy after 5 epochs of no improvement in total loss for validation set\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Always save the best model\n",
    "saving_cb = ModelCheckpoint(\n",
    "    filepath='../trained_models/pascal_yolo_model/best_weights.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss', \n",
    "    mode='min',  \n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Use the PyCOCO metrics callback to track the mAP across different box sizes for all classes\n",
    "metrics_cb = keras_cv.callbacks.PyCOCOCallback(\n",
    "    ds_val.take(20), bounding_box_format=\"xywh\"\n",
    ")\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate= config['learning_rate'],\n",
    "                                         global_clipnorm= config['global_clipnorm']),\n",
    "              classification_loss= 'binary_crossentropy',\n",
    "              box_loss=\"ciou\")\n",
    "history = model.fit(ds_val.take(5), validation_data= ds_val.take(5), epochs = 1, callbacks = [early_stopping, \n",
    "                                                                                                      saving_cb, \n",
    "                                                                                                      metrics_cb])\n",
    "\n",
    "# Save the model\n",
    "model.save(\"../trained_models/pascal_yolo_model/saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "with plt.style.context('dark_background'):\n",
    "    plot_loss(history, model_type= 'object_detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a trained model and predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model and visualize predictions\n",
    "from keras.models import load_model\n",
    "\n",
    "trained_model = load_model('computer_vision/trained_models/pascal_yolo_model')\n",
    "\n",
    "with plt.style.context('dark_background'):\n",
    "    visualize_object_predictions(trained_model, dataset= ds_test, bounding_box_format='xywh', class_mapping= get_class_mapping(ds_info))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
