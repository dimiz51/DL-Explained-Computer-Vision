{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from helper import fast_benchmark, set_model_config\n",
    "from helper import plot_loss\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_cv\n",
    "from keras_cv import visualization\n",
    "from keras_cv import bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config  = set_model_config(model_name='pascal_yolo')\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Pascal-Voc dataset\n",
    "\n",
    "# Visualize the Keras-CV compatible dataset\n",
    "def visualize_object_detection_samples(inputs, value_range, rows, cols, bounding_box_format, class_mapping):\n",
    "    inputs = next(iter(inputs.take(1)))\n",
    "    images, bounding_boxes = inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=value_range,\n",
    "        rows=rows,\n",
    "        cols=cols,\n",
    "        y_true=bounding_boxes,\n",
    "        scale=5,\n",
    "        font_scale=0.7,\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        class_mapping=class_mapping,\n",
    "    )\n",
    "\n",
    "# Get the class mapping dictionary\n",
    "def get_class_mapping(dataset_info):\n",
    "    class_mapping = {i: class_info for i, class_info in enumerate(dataset_info.features['objects']['label'].names)}\n",
    "    return class_mapping\n",
    "\n",
    "\n",
    "# Unpackage the raw tfdf formats into Keras-CV format\n",
    "def unpackage_raw_tfds_inputs(inputs, bounding_box_format):\n",
    "    image = inputs[\"image\"]\n",
    "    boxes = keras_cv.bounding_box.convert_format(\n",
    "        inputs[\"objects\"][\"bbox\"],\n",
    "        images=image,\n",
    "        source=\"rel_yxyx\",\n",
    "        target=bounding_box_format,\n",
    "    )\n",
    "    bounding_boxes = {\n",
    "        \"classes\": tf.cast(inputs[\"objects\"][\"label\"], dtype=tf.float32),\n",
    "        \"boxes\": tf.cast(boxes, dtype=tf.float32),\n",
    "    }\n",
    "    return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}\n",
    "\n",
    "# Unpack batch from dataset to tuple format function\n",
    "def unpack_batch_dicts(inputs):\n",
    "    return inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "\n",
    "# Custom dataloader, compatible with Keras-CV, applies shuffling and batching\n",
    "def load_pascal_voc(split, dataset, bounding_box_format):\n",
    "    ds, ds_info  = tfds.load(dataset, split=split, with_info=True, shuffle_files=True)\n",
    "    \n",
    "    # Convert the images/bboxes to the Keras-CV API format\n",
    "    ds = ds.map(\n",
    "        lambda x: unpackage_raw_tfds_inputs(x, bounding_box_format=bounding_box_format),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "    \n",
    "    if split != 'test':\n",
    "        ds = ds.shuffle(config['batch_size'] * 4, reshuffle_each_iteration=True)\n",
    "    \n",
    "    # Create ragged batches(with elems of different sizes)\n",
    "    ds = ds.ragged_batch(config['batch_size'], drop_remainder=True)\n",
    "    \n",
    "    return ds,ds_info\n",
    "\n",
    "# Define augmenter module using custom object detection friendly ops from Keras-CV\n",
    "augmenter = keras.Sequential(\n",
    "    layers=[\n",
    "        keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xywh\"),\n",
    "        keras_cv.layers.RandomShear(\n",
    "            x_factor=0.2, y_factor=0.2, bounding_box_format=\"xywh\"\n",
    "        ),\n",
    "        keras_cv.layers.JitteredResize(\n",
    "            target_size=(480, 480), scale_factor=(0.75, 1.3), bounding_box_format=\"xywh\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# # Inference inputs pre-processing for our test and validation sets\n",
    "inf_preprocess = keras_cv.layers.JitteredResize(target_size=(480, 480),\n",
    "                                              scale_factor=(0.75, 1.3),\n",
    "                                              bounding_box_format=\"xywh\",\n",
    "                                            )\n",
    "\n",
    "# Load the three different pre-processed splits of our dataset\n",
    "ds_train, ds_info = load_pascal_voc(\n",
    "    split=\"train\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"\n",
    ")\n",
    "ds_val, _ = load_pascal_voc(\n",
    "    split=\"validation\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"\n",
    ")\n",
    "ds_test, _ = load_pascal_voc(\n",
    "    split=\"test\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"\n",
    ")\n",
    "\n",
    "# Apply augmentations and set prefetch option on training set\n",
    "ds_train = ds_train.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.map(unpack_batch_dicts, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Pre-process validation and test set\n",
    "ds_val = ds_val.map(inf_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.map(unpack_batch_dicts, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(inf_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.shuffle(ds_info.splits['test'].num_examples)\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----Pascal-Voc dataset information-----:\")\n",
    "print(f\"Number of training examples: {ds_info.splits['train'].num_examples}\")\n",
    "print(f\"Number of validation examples: {ds_info.splits['validation'].num_examples}\")\n",
    "print(f\"Number of test examples: {ds_info.splits['test'].num_examples}\")\n",
    "print(f\"Dataset splits available: {list(ds_info.splits.keys())}\")\n",
    "print(\"Number of Classes:\", len(ds_info.features[\"objects\"][\"label\"].names))\n",
    "print(f\"Class names: {ds_info.features['objects']['label'].names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some samples from the dataset\n",
    "with plt.style.context('dark_background'):\n",
    "    visualize_object_detection_samples(ds_train, value_range=(0, 255), rows=2, cols=4, bounding_box_format=\"xywh\", class_mapping=get_class_mapping(ds_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained, on the CoCo dataset, YoloV8 model\n",
    "backbone =  keras_cv.models.YOLOV8Backbone.from_preset(\"yolo_v8_xs_backbone\")\n",
    "backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our custom YOLO model from the smallest available backbone\n",
    "model = keras_cv.models.YOLOV8Detector(\n",
    "    num_classes=len(get_class_mapping(ds_info)),\n",
    "    bounding_box_format=\"xywh\",\n",
    "    backbone=backbone,\n",
    "    fpn_depth = 1\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and configure the model for training\n",
    "if config['optimizer'].lower() == 'adam':\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= config['learning_rate'],\n",
    "                                      global_clipnorm= config['global_clipnorm'])\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer=optimizer,\n",
    "              classification_loss= 'binary_crossentropy',\n",
    "              box_loss=\"ciou\")\n",
    "history = model.fit(ds_train, validation_data= ds_val, epochs = config['training_epochs'])\n",
    "\n",
    "# Plot with dark background\n",
    "with plt.style.context('dark_background'):\n",
    "    plot_loss(history, model_type = 'object_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model and visualize predictions\n",
    "from keras.models import load_model\n",
    "\n",
    "test_iterator = iter(ds_test.take(1))\n",
    "single_image = next(test_iterator)[0]\n",
    "\n",
    "# Load a trained model and visualize predictions\n",
    "# trained_model = load_model('computer_vision/trained_models/pascal_yolo_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
